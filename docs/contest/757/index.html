<!doctype html>
<html lang="en">

<head>
	<title>Attempt #1: Zero-Shot</title><meta charset="utf-8" data-svelte="svelte-t170d2"><meta name="viewport" content="width=device-width, initial-scale=1.0" data-svelte="svelte-t170d2"><meta http-equiv="Content-Type" content="text/html; charset=utf-8" data-svelte="svelte-t170d2"><meta name="description" content="Help a Computer Win the New Yorker Cartoon Caption Contest" data-svelte="svelte-t170d2"><meta name="author" content="The Pudding" data-svelte="svelte-t170d2"><meta name="news_keywords" content="" data-svelte="svelte-t170d2"><meta property="og:title" content="Attempt #1: Zero-Shot" data-svelte="svelte-t170d2"><meta property="og:site_name" content="The Pudding" data-svelte="svelte-t170d2"><meta property="og:url" content="https://pudding.cool/projects/caption-contest" data-svelte="svelte-t170d2"><meta property="og:description" content="Help a Computer Win the New Yorker Cartoon Caption Contest" data-svelte="svelte-t170d2"><meta property="og:type" content="article" data-svelte="svelte-t170d2"><meta property="og:locale" content="en_US" data-svelte="svelte-t170d2"><meta property="og:image" content="https://pudding.cool/projects/caption-contest/assets/social/facebook.png" data-svelte="svelte-t170d2"><meta property="og:image:type" content="image/jpeg" data-svelte="svelte-t170d2"><meta property="og:image:width" content="1200" data-svelte="svelte-t170d2"><meta property="og:image:height" content="600" data-svelte="svelte-t170d2"><meta name="twitter:card" content="summary_large_image" data-svelte="svelte-t170d2"><meta name="twitter:site" content="https://pudding.cool" data-svelte="svelte-t170d2"><meta name="twitter:creator" content="@puddingviz" data-svelte="svelte-t170d2"><meta name="twitter:title" content="Attempt #1: Zero-Shot" data-svelte="svelte-t170d2"><meta name="twitter:description" content="Help a Computer Win the New Yorker Cartoon Caption Contest" data-svelte="svelte-t170d2"><meta name="twitter:image:src" content="https://pudding.cool/projects/caption-contest/assets/social/twitter.png" data-svelte="svelte-t170d2"><meta name="robots" content="max-image-preview:large" data-svelte="svelte-t170d2"><link rel="canonical" href="https://pudding.cool/projects/caption-contest/" data-svelte="svelte-t170d2">

		

		<link rel="modulepreload" href="/projects/caption-contest/_app/start-dd246be1.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/chunks/vendor-c611dbfe.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/chunks/preload-helper-9f12a5fd.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/chunks/paths-45dac81d.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/pages/__layout.svelte-3e0f6a54.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/chunks/wordmark-0849a013.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/pages/contest/[slug].svelte-32be62dc.js">
		<link rel="modulepreload" href="/projects/caption-contest/_app/chunks/doc-de448dd2.js">
		<link rel="stylesheet" href="/projects/caption-contest/_app/assets/start-9aa571ba.css">
		<link rel="stylesheet" href="/projects/caption-contest/_app/assets/pages/__layout.svelte-ec942cfa.css">
		<link rel="stylesheet" href="/projects/caption-contest/_app/assets/pages/contest/[slug].svelte-59b8d630.css">

		<script type="module">
			import { start } from "/projects/caption-contest/_app/start-dd246be1.js";
			start({
				target: document.querySelector("#svelte"),
				paths: {"base":"/projects/caption-contest","assets":"/projects/caption-contest"},
				session: {},
				host: location.host,
				route: true,
				spa: false,
				trailing_slash: "always",
				hydrate: null
			});
		</script>
</head>

<body>
	<a href="#content" class="skip-to-main">Skip to main content</a>
	<div id="svelte">


<main id="content"><header class="svelte-1qpkk0e"><div class="col"><div class="wordmark svelte-1qpkk0e"><a href="https://pudding.cool" aria-label="The Pudding" class="svelte-1qpkk0e"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 192.6 50"><path class="st0" d="M150.1 9.5c1.5 0 2.8 1.3 2.8 2.8s-1.3 2.8-2.8 2.8-2.8-1.3-2.8-2.8 1.3-2.8 2.8-2.8zM147.2 17.3h5.6v18.2h-5.6V17.3zM77.1 9.5h-8.9v26h5.6v-8.1h3.3c4.9 0 8.9-4 8.9-8.9s-3.9-9-8.9-9zm0 12.3h-3.3v-6.6h3.3c1.8 0 3.3 1.5 3.3 3.3s-1.4 3.3-3.3 3.3zM105.7 17.6h-5.6v8.9c0 1.8-1.5 3.3-3.3 3.3s-3.3-1.5-3.3-3.3v-8.9h-5.6v8.9c0 4.9 4 8.9 8.9 8.9s8.9-4 8.9-8.9v-8.9zM164.1 17.6c-4.9 0-8.9 4-8.9 8.9v8.9h5.6v-8.9c0-1.8 1.5-3.3 3.3-3.3s3.3 1.5 3.3 3.3v8.9h5.6v-8.9c0-4.9-4-8.9-8.9-8.9zM119.7 16.2v1.4h-3.3c-4.9 0-8.9 4-8.9 8.9s4 8.9 8.9 8.9h8.9V9.5l-5.6 3.3v3.4zm.1 8.4V29.8h-3.3c-1.8 0-3.3-1.5-3.3-3.3s1.5-3.3 3.3-3.3h3.3v1.4zM139.3 16.2v1.4H136c-4.9 0-8.9 4-8.9 8.9s4 8.9 8.9 8.9h8.9V9.5l-5.6 3.3v3.4zm.1 8.4V29.8H136c-1.8 0-3.3-1.5-3.3-3.3s1.5-3.3 3.3-3.3h3.3v1.4h.1zM183.7 17.6c-4.9 0-8.9 4-8.9 8.9s4 8.9 8.9 8.9h3.3v5.1c0 1.8-1.5 3.3-3.3 3.3s-3.3-1.5-3.3-3.3V38l-5.6 3.3c.4 4.5 4.2 8.1 8.9 8.1 4.9 0 8.9-4 8.9-8.9V17.6h-8.9zm3.3 5.8V30h-3.3c-1.8 0-3.3-1.5-3.3-3.3s1.5-3.3 3.3-3.3h3.3zM28.6 17.6c-1.2 0-2.3.2-3.3.6V9.5l-5.6 3.3v22.6h5.6v-8.9c0-1.8 1.5-3.3 3.3-3.3s3.3 1.5 3.3 3.3v8.9h5.6v-8.9c0-4.9-4-8.9-8.9-8.9zM17.8 9.5H0v5.6h6.1v20.3h5.6V15.1h6.1V9.5zM48.3 30.2c-.4 0-1.2-.1-1.8-.4l5.2-2.1 5.6-2.3-1-2.3-.1-.2c-.1-.3-.3-.6-.5-1-.1-.1-.1-.2-.2-.3 0 0 0-.1-.1-.1l-.1-.1-.1-.1c-1.6-2.2-4-3.5-6.7-3.7h-.6c-4.9 0-8.9 4-8.9 8.9 0 .4 0 .9.1 1.4V28.2c0 .3.1.5.2.8v.2c.1.3.2.7.4 1v.2c.1.3.3.5.4.8 0 .1.1.1.1.2.1.2.3.4.4.6v.1s0 .1.1.1l.1.1c1.7 2.1 4.4 3.4 7.2 3.4h6.1v-5.2c.4-.3-3.5-.3-5.8-.3zm7.9-7.3zm-11.6 2.8l-.2.1c.2-1.9 1.8-3.5 3.7-3.5.9 0 1.8.4 2.4.9L46.2 25l-1.6.7z"/></svg></a></div></div>
</header>

  

<section style="--theme: var(--theme-1);" class="svelte-bxxmu9"><div class="info svelte-bxxmu9"><div class="col"><h1 class="svelte-bxxmu9">Attempt #1: Zero-Shot</h1>
      <time>May 24, 2021</time>
      <p>We used a process that we’re calling <strong>The Zero-Shot</strong>. We gave a description of the image and some context of our goal to a computer model to generate the results.</p>
      <a href="/projects/caption-contest/" class="svelte-bxxmu9">Back to Project</a></div></div>

  <div class="col"><figure class="svelte-bxxmu9"><figcaption class="sm svelte-bxxmu9"><a href="https://www.newyorker.com/cartoons/contest" class="svelte-bxxmu9">#757</a>: Here is the cartoon for
        May 24, 2021 by Carolita Johnson</figcaption>
      <img src="https://media.newyorker.com/cartoons/60a82e3e3cb60a570a4df64e/master/w_1160,c_limit/210531_a25180_757.jpg" alt="captionless cartoon by Carolita Johnson" class="svelte-bxxmu9"></figure>

    <div class="submission"><p><strong>Our submission:</strong> “I’m sorry about this whole climate change thing.”</p>
      <details class="sm svelte-bxxmu9"><summary><span>Check out all three generated captions.</span></summary>
          <span><p class="svelte-bxxmu9"><strong>The weather was awful and he was so boring.</strong></p>
              <p class="result svelte-bxxmu9">7% of readers thought it was funny.</p><p class="svelte-bxxmu9"><strong>“I’m sorry about this whole climate change thing.”</strong></p>
              <p class="result svelte-bxxmu9">25% of readers thought it was funny.</p><p class="svelte-bxxmu9"><strong>“The best case scenario is that those are just rainclouds. If not, I&#39;ll have to figure out how to keep my margarita from spilling.”</strong></p>
              <p class="result svelte-bxxmu9">12% of readers thought it was funny.</p></span></details></div>

    <div class="explanation sm"><h2 class="svelte-bxxmu9">About this approach</h2>
      <p>To produce the captions this week we “prompted” the GPT-3 model, davinci-instruct-beta, through the <a href=https://openai.com/>OpenAI API Playground</a>. This model is specially trained to “follow instructions,” so we gave it the instruction “Write a funny caption for a New Yorker cartoon” plus a description we wrote of the cartoon illustrated by Carolita Johnson. The model parameters were set to their defaults.</p><p>In machine learning <a href=https://en.wikipedia.org/wiki/Zero-shot_learning>zero-shot learning</a> refers to a paradigm where a model solely relies on its general knowledge of the world to solve a problem at test time. Say we play you a song by Olivia Rodrigo but you’ve never heard her music before. Can you guess that she’s the singer? What if you’ve heard a lot of Taylor Swift songs and have read a review of “drivers license” that talks about Olivia Rodrigo and her Swift-ian inspirations?</p><p>GPT-3 has never seen this particular description of a New Yorker cartoon. But it has read a lot of text on the internet that has described New Yorker cartoons and their captions. It’s also read a lot of New Yorker articles and has some understanding of the magazine’s readership and what they find interesting or funny. It has generally seen a lot of comics with associated text so presumably understands what is meant by a “cartoon caption.” Here is the full prompt:</p><p><blockquote>Write a funny caption for a New Yorker cartoon.<br>"""<br>Cartoon description: A man and a woman are having a picnic in a park. The man is talking. There are anthropomorphic clouds that are angry.<br>Cartoon caption:</blockquote></p><p>That’s it! And GPT-3 fills in the blank.</p>
      <p><a href="/projects/caption-contest/" class="svelte-bxxmu9">Back to Project</a></p></div></div>
</section></main>



	
</div>
	<!-- <script async src="https://platform.instagram.com/en_US/embeds.js"></script> -->
</body>


</html>